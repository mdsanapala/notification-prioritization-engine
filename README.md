ğŸ“¢ Notification Prioritization Engine

An intelligent, explainable backend system that classifies incoming notification events into:

<<<<<<< HEAD
=======

>>>>>>> 2eaae1ffaab493acbfca0df753560b227e9fc89d
âœ… NOW (send immediately)

â³ LATER (deferred / scheduled)

âŒ NEVER (suppressed)

The system reduces notification overload using:

Hard override rules

TTL-based duplicate suppression

Alert fatigue control

AI-assisted scoring

Persistent audit logging

Explainable decision outputs

ğŸš€ Problem Statement

Modern applications send notifications from multiple sources (messages, alerts, promotions, system events). Users often experience:

Too many notifications

Duplicate messages

Low-value spam

Important alerts being delayed

Notification fatigue

This engine ensures:

Important notifications are prioritized

Duplicates are suppressed

Alert fatigue is minimized

Every decision is explainable and auditable

The system fails safely under dependency issues

ğŸ— High-Level Architecture
<<<<<<< HEAD
=======

>>>>>>> 2eaae1ffaab493acbfca0df753560b227e9fc89d
Incoming Event
      â”‚
      â–¼
API Layer (FastAPI)
      â”‚
      â–¼
Decision Engine
 â”œâ”€â”€ Expiry Check
 â”œâ”€â”€ Critical Override
 â”œâ”€â”€ Deduplication (TTL)
 â”œâ”€â”€ Rule-Based Scoring
 â”œâ”€â”€ Fatigue Penalty
 â”œâ”€â”€ AI Score
      â”‚
      â–¼
Final Classification
(NOW / LATER / NEVER)
      â”‚
      â–¼
Audit Log (SQLite)
ğŸ§  Decision Logic Strategy

The decision pipeline follows this strict order:

1ï¸âƒ£ Expiry Check

If expires_at < current_time â†’ NEVER

2ï¸âƒ£ Critical Override

If priority_hint == critical â†’ NOW

3ï¸âƒ£ Duplicate Suppression

TTL-based (5 minutes) suppression using:

dedupe:{user_id}:{message}

If duplicate â†’ NEVER

4ï¸âƒ£ Scoring System
Final Score = Rule Score + AI Score - Fatigue Penalty
Score Range	Decision
> 75	NOW
40â€“75	LATER
< 40	NEVER
ğŸ§¾ API Interfaces (5 Endpoints)
1ï¸âƒ£ POST /notifications

Main decision endpoint.

Request
{
  "user_id": "u123",
  "event_type": "alert",
  "message": "Server Down!",
  "source": "system",
  "priority_hint": "critical",
  "timestamp": "2026-02-26T10:00:00",
  "channel": "push"
}
Response
{
  "event_id": "uuid",
  "decision": "NOW",
  "reason": "Critical priority override",
  "explanation": {}
}
2ï¸âƒ£ GET /audit/{event_id}

Retrieve stored decision for transparency.

3ï¸âƒ£ GET /health

Health check endpoint.

4ï¸âƒ£ GET /metrics

Returns decision distribution & monitoring statistics.

5ï¸âƒ£ POST /rules/update

Supports dynamic rule configuration without redeployment.

ğŸ—„ Data Model
NotificationEvent

user_id

event_type

message

source

priority_hint

timestamp

channel

expires_at (optional)

AuditLog

event_id (UUID)

user_id

decision

reason

explanation (JSON)

created_at

ğŸ” Duplicate Prevention Strategy

Uses 5-minute TTL window

Suppresses repeated notifications

Prevents spam bursts

Designed to scale with Redis (future upgrade)

ğŸ”” Alert Fatigue Strategy

Tracks per-user notification count

Applies penalty after threshold

Reduces noisy, low-priority events

Protects user experience

ğŸ§  AI Scoring Layer

AI scoring component evaluates likelihood of engagement

Combined with rule score

Designed to fallback safely if AI service fails

ğŸ›¡ Fail-Safe Strategy

If any dependent component fails:

AI failure â†’ fallback to rule score

DB failure â†’ decision still returned, error logged

Redis failure â†’ fallback to in-memory dedupe

System always returns a decision (no silent drops)

ğŸ“Š Monitoring & Metrics Plan

System designed to support:

Decision distribution tracking

Duplicate rate monitoring

Fatigue-trigger frequency

Latency monitoring

Error rate tracking

âš™ï¸ Tech Stack

Python

FastAPI

SQLAlchemy

SQLite

Pydantic

Redis (scalable dedupe)

APScheduler (optional scheduling)

scikit-learn (AI scoring)

ğŸš€ Running Locally
1ï¸âƒ£ Install dependencies
pip install -r requirements.txt
2ï¸âƒ£ Run server
uvicorn app.main:app --reload
3ï¸âƒ£ Access docs
http://127.0.0.1:8000/docs
ğŸ“ˆ Future Improvements

Redis cluster support

Distributed deployment

Background worker for LATER queue

Real-time push integration

ML model training dashboard

Rate-limiting per channel

User preference learning

ğŸ¯ Design Principles

Explainability first

Deterministic decision order

Modular architecture

Extensible scoring system

Audit-compliant logging

Scalability-ready design

ğŸ‘¨â€ğŸ’» Author

Murali Dharan Sanapala
AI/ML & Backend Engineering Enthusiast

ğŸ Summary


